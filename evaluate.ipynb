{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9f9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfoldx.structure import Structure\n",
    "import torch\n",
    "from predict import *\n",
    "import torch.optim as optim\n",
    "import torch.nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f353a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights/HERN_dock.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f025964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(pdb, cdr3, model):\n",
    "    dock(pdb, cdr3, model, relax=True)\n",
    "    struct = Structure(code='', path='outputs/docked.pdb')\n",
    "    interaction_energy = struct.getInterfaceEnergy()['Interaction Energy'][-1]\n",
    "    \n",
    "    return float(interaction_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94486fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b0e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int):\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6930337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d_model = 1\n",
    "        self.embedding = nn.Embedding(20, 32)\n",
    "        self.pos_encoder = PositionalEncoding(1)\n",
    "        encoder_layers = TransformerEncoderLayer(32, 8, 64, 0.1)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, 1)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6093ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureCritic(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.critic_encoder = CriticEncoder()\n",
    "        \n",
    "        self.dense_layers = nn.ModuleList([nn.Linear(32, 20) for _ in range(seq_len)])\n",
    "        self.softmax_layers = nn.ModuleList([nn.Softmax(dim=1) for _ in range(seq_len)])\n",
    "        \n",
    "        self.linear_predict = nn.Linear(seq_len, 1)\n",
    "    \n",
    "    def forward(self, src, src_mask):\n",
    "        dists = []\n",
    "        sequence = []\n",
    "        X = self.critic_encoder(src, src_mask)\n",
    "        \n",
    "        for residue, dense, softmax in zip(X, self.dense_layers, self.softmax_layers):\n",
    "            out = dense(residue)\n",
    "            policy_dist = softmax(out)\n",
    "            dists.append(policy_dist)\n",
    "        \n",
    "        value = self.linear_predict(torch.tensor(src.t()).float())\n",
    "        \n",
    "        return dists, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e48e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing complex energy for structure...\n",
      "Energy computed.\n"
     ]
    }
   ],
   "source": [
    "# Use CondRefineGNN to generate CDR3 sequences\n",
    "\n",
    "sample_cdr3 = 'AAAAAAAAAAAAA'\n",
    "sample_out = reward('1nca_imgt.pdb', sample_cdr3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5a421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([ALPHABET.index(a) for a in sample_cdr3]).unsqueeze(1).long()\n",
    "Y = sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e1eead0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(988.9739, grad_fn=<AddBackward0>)\n",
      "tensor(991.3818, grad_fn=<AddBackward0>)\n",
      "tensor(986.7454, grad_fn=<AddBackward0>)\n",
      "tensor(984.9760, grad_fn=<AddBackward0>)\n",
      "tensor(981.1136, grad_fn=<AddBackward0>)\n",
      "tensor(981.6342, grad_fn=<AddBackward0>)\n",
      "tensor(979.4203, grad_fn=<AddBackward0>)\n",
      "tensor(978.9031, grad_fn=<AddBackward0>)\n",
      "tensor(980.1447, grad_fn=<AddBackward0>)\n",
      "tensor(973.5017, grad_fn=<AddBackward0>)\n",
      "tensor(974.2394, grad_fn=<AddBackward0>)\n",
      "tensor(982.7502, grad_fn=<AddBackward0>)\n",
      "tensor(975.6188, grad_fn=<AddBackward0>)\n",
      "tensor(974.9247, grad_fn=<AddBackward0>)\n",
      "tensor(973.9822, grad_fn=<AddBackward0>)\n",
      "tensor(974.0204, grad_fn=<AddBackward0>)\n",
      "tensor(970.6610, grad_fn=<AddBackward0>)\n",
      "tensor(976.1815, grad_fn=<AddBackward0>)\n",
      "tensor(971.5253, grad_fn=<AddBackward0>)\n",
      "tensor(971.1320, grad_fn=<AddBackward0>)\n",
      "tensor(972.0148, grad_fn=<AddBackward0>)\n",
      "tensor(970.5977, grad_fn=<AddBackward0>)\n",
      "tensor(964.1851, grad_fn=<AddBackward0>)\n",
      "tensor(968.2761, grad_fn=<AddBackward0>)\n",
      "tensor(964.9650, grad_fn=<AddBackward0>)\n",
      "tensor(967.2667, grad_fn=<AddBackward0>)\n",
      "tensor(960.6548, grad_fn=<AddBackward0>)\n",
      "tensor(961.1140, grad_fn=<AddBackward0>)\n",
      "tensor(960.2699, grad_fn=<AddBackward0>)\n",
      "tensor(960.3473, grad_fn=<AddBackward0>)\n",
      "tensor(959.9608, grad_fn=<AddBackward0>)\n",
      "tensor(961.3076, grad_fn=<AddBackward0>)\n",
      "tensor(958.7264, grad_fn=<AddBackward0>)\n",
      "tensor(960.3392, grad_fn=<AddBackward0>)\n",
      "tensor(959.9446, grad_fn=<AddBackward0>)\n",
      "tensor(959.0802, grad_fn=<AddBackward0>)\n",
      "tensor(960.4341, grad_fn=<AddBackward0>)\n",
      "tensor(959.7589, grad_fn=<AddBackward0>)\n",
      "tensor(960.6122, grad_fn=<AddBackward0>)\n",
      "tensor(960.9895, grad_fn=<AddBackward0>)\n",
      "tensor(958.5325, grad_fn=<AddBackward0>)\n",
      "tensor(958.6549, grad_fn=<AddBackward0>)\n",
      "tensor(961.0879, grad_fn=<AddBackward0>)\n",
      "tensor(960.4038, grad_fn=<AddBackward0>)\n",
      "tensor(960.4223, grad_fn=<AddBackward0>)\n",
      "tensor(959.0509, grad_fn=<AddBackward0>)\n",
      "tensor(961.7491, grad_fn=<AddBackward0>)\n",
      "tensor(960.7640, grad_fn=<AddBackward0>)\n",
      "tensor(960.3360, grad_fn=<AddBackward0>)\n",
      "tensor(961.2468, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/r_p9zjzd0cgg0qh2y3ltj6gh0000gn/T/ipykernel_47994/4277621281.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = self.linear_predict(torch.tensor(src.t()).float())\n"
     ]
    }
   ],
   "source": [
    "structure_critic = StructureCritic(X.shape[0])\n",
    "optimizer = optim.Adam(structure_critic.parameters())\n",
    "\n",
    "'''\n",
    "A2C https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f\n",
    "\n",
    "advantage = Y - value\n",
    "actor_loss = (-log_probs * advantage).mean()\n",
    "critic_loss = 0.5 * advantage.pow(2).mean()\n",
    "\n",
    "loss = actor_loss + critic_loss\n",
    "loss.backward()\n",
    "\n",
    "''' \n",
    "\n",
    "for i in range(50):\n",
    "    dists, value = structure_critic(X, generate_square_subsequent_mask(X.shape[0]))\n",
    "    log_probs = torch.log((torch.stack(dists))).sum(dim=0)\n",
    "    advantage = Y - value\n",
    "\n",
    "    log_loss = (-log_probs * advantage).mean()\n",
    "    critic_loss = 0.5 * advantage.pow(2).mean()\n",
    "    loss = log_loss + critic_loss\n",
    "    print(loss)\n",
    "\n",
    "    optimizer.zero_grad\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "121d692f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPAPSRQAHSNGN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/r_p9zjzd0cgg0qh2y3ltj6gh0000gn/T/ipykernel_47994/4277621281.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = self.linear_predict(torch.tensor(src.t()).float())\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X = torch.tensor([ALPHABET.index(a) for a in '#############']).unsqueeze(1).long()\n",
    "    dists, value = structure_critic(X, generate_square_subsequent_mask(X.shape[0]))\n",
    "    seq = [torch.argmax(dist).item() for dist in dists]\n",
    "    print(''.join([ALPHABET[aa] for aa in seq]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
